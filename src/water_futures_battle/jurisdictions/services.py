import os
from pathlib import Path
from typing import Any, Dict, List, Set, Tuple

import numpy as np
import pandas as pd

from ..core import Settings, get_snapshot
from ..core.utility import timestampify
from ..core.base_model import StaticProperties

from ..nrw_model.enums import NRWClass
from ..nrw_model.dynamic_properties import NRWModelDB
from ..water_demand_model import WaterDemandModelData
from ..water_demand_model.properties import WaterDemandModelDB
from ..water_demand_model.services import modulate_business_pattern, modulate_house_pattern

from .dynamic_properties import MunicipalitiesDB as MuniDB, MunicipalitiesResults as MuniR
from .entities import (
    State, Region, Province, Municipality, 
)

def build_state(
        config: dict[str,str], 
        data_path: str,
        settings: Settings
    ) -> State:
    """
    Build a state from a config dictionary.

    Args:
        config (dict): Configuration dictionary.

    Returns:
        State: A state object 
    """
    name = config['name']
    identifier = config['id']

    # This module need a random generator, let's get it from the settings
    RNG_RES_P_WEIGHT = settings.get_random_generator('municipalities-res_p_weight')

    # Get the dynamic properties search within the `files` properties, the following:
    # - municipalities-dynamic_properties
    # upload the metadata...
    munis_db = MuniDB.load_from_file(os.path.join(data_path, Path(config[MuniDB.NAME])))

    # Inject the dynamic properties and the repository into the jurisdiciton classes
    Municipality.set_dynamic_properties(munis_db)
    Municipality.set_results(MuniR())
    
    # Creation order is State, Regions, Provinces, Municipalities.
    # Every Jurisdictions will register itself to the correct parent automatically

    # Let's upload the static properties explaining the jurisdictions
    jurisdictions_sheets = pd.read_excel(os.path.join(data_path, Path(config['jurisdictions-static_properties'])), sheet_name=None)    

    # Assume we uploaded the 'state' and it only has this:
    a_state = State(name, identifier)

    for _, a_region_data in jurisdictions_sheets['regions'].iterrows():
        assert a_region_data['state'] == identifier
        Region.from_row(row_data=a_region_data.to_dict(), state=a_state)

    for _, a_province_data in jurisdictions_sheets['provinces'].iterrows():
        province_s_region = a_state.region(a_province_data['region'])
        Province.from_row(row_data=a_province_data.to_dict(), region=province_s_region)

    for _, a_municipality_data in jurisdictions_sheets['municipalities'].iterrows():

        municipality_s_province = a_state.province(a_municipality_data['province'])
        Municipality.from_row(
            row_data=a_municipality_data.to_dict(),
            province=municipality_s_province,
            _res_p_weight=RNG_RES_P_WEIGHT.uniform(low=0, high=1, size=1).item()
        
        )

    return a_state

def dump_state(
        a_state: State,
        output_dir: Path
    ) -> Dict[str, Any]:

    full_out_dir = output_dir / "jurisdictions"
    def as_rel_path(a_path: Path) -> str:
        return os.path.relpath(a_path, output_dir)

    states_df = {
        "regions": pd.DataFrame(data=[m.to_dict() for m in a_state.regions]).sort_values('cbs_id'),
        "provinces": pd.DataFrame(data=[m.to_dict() for m in a_state.provinces]).sort_values('cbs_id'),
        "municipalities": pd.DataFrame(data=[m.to_dict() for m in a_state.municipalities]).sort_values('name')
    }

    state_properties = StaticProperties(
        name="jurisdictions-static_properties",
        dataframes=states_df
    )

    sp_path = state_properties.dump(full_out_dir)

    dp_path = Municipality._dynamic_properties.dump(full_out_dir)

    return {
        "name": a_state._base_name,
        "id": a_state.cbs_id,
        state_properties.name: as_rel_path(sp_path),
        MuniDB.NAME: as_rel_path(dp_path)
    }

def generate_nrw_demand(
        municipality: Municipality,
        year: int,
        nrw_info_db: NRWModelDB,
        water_demand: np.ndarray,
        settings: Settings
    ) -> np.ndarray:
    """
    Generates additional NRW demands for a given municipality.

    Parameters
    ----------
    municipality : :class:`Municipality`
        The municipality for which we have to generate nrw demands.
    nrw_info_db : :class:`NRWModelDB`
        NRW model database.
    water_demand : numpy.ndarray
        Hourly water demands as generated by the water demand module.

    Returns
    -------
    `list[float]`
        NRW demands for one year in m^3/h (365 values).
    """
    muni_y = get_snapshot(municipality, year)

    # Compute number of pipe kilometers
    pipes_km = muni_y.dist_network_length

    # Get current nrw class
    nrw_class: NRWClass = muni_y.nrw_class

    # Average hourly water demands per day
    avg_water_demand = []
    for i in range(0, len(water_demand), 24):
        avg_water_demand.append(float(np.mean(water_demand[i:i+24])))   # daily average m^3/hour
    avg_water_demand = np.array(avg_water_demand)

    # Compute daily nrw demands (for one year) by sampling from the base demand (returns m^3/km/day)
    RNG = settings.get_random_generator('nrw_model-sample_demand')
    nrw = pipes_km * nrw_class.sample_demand(n_points=365, RNG=RNG) # m^3/day
    nrw = nrw/24 # m^3/hour

    # Upperbound on nrw demand: 2 * normal water demand
    mask = nrw > 2. * avg_water_demand
    nrw[mask] = 2. * avg_water_demand[mask]

    return nrw

def generate_water_demand(
        wdm_data: WaterDemandModelData,
        municipality: Municipality,
        year: int,
        max_yearly_temperature: float,
        settings: Settings
    ) -> Tuple[np.ndarray, np.ndarray]:

    munic_Y = get_snapshot(municipality, year)
    wdm_patterns, wdm_db = wdm_data

    # Get the random generator for this module
    RNG = settings.get_random_generator('water_demand_model-sample_demand')

    # get the 3 indexes of the patterns to take from the database
    (pattern_id_h1, pattern_id_h2), pattern_id_b = munic_Y.assigned_demand_patterns

    # get the weights used to balance the two residential profiles
    w_h1, w_h2 = munic_Y.assigned_res_patterns_weights

    # get the number of houses and businesses in year y of municipality m 
    n_houses = munic_Y.n_houses
    n_businesses = munic_Y.n_businesses

    # get the 3 selected patterns (returns adimensional values with mean 1)
    pattern_h1 = wdm_patterns[pattern_id_h1].values
    pattern_h2 = wdm_patterns[pattern_id_h2].values
    pattern_b = wdm_patterns[pattern_id_b].values

    # modulate the 3 patterns using temperature and other static properties
    pattern_h1 = modulate_house_pattern(pattern_h1, max_yearly_temperature, RNG)
    pattern_h2 = modulate_house_pattern(pattern_h2, max_yearly_temperature, RNG)
    pattern_b = modulate_business_pattern(pattern_b, RNG)

    # get the per_house_demand and per_business_demand in year y (uncertain)
    ts = timestampify(year, errors='raise')
    per_house_bounds = wdm_db[WaterDemandModelDB.PER_HOUSE_DEMAND][['NL0000-min', 'NL0000-max']].asof(ts)
    per_business_bounds = wdm_db[WaterDemandModelDB.PER_BUSINESS_DEMAND][['NL0000-min', 'NL0000-max']].asof(ts)

    per_house_demand = RNG.uniform(per_house_bounds['NL0000-min'], per_house_bounds['NL0000-max'])
    per_business_demand = RNG.uniform(per_business_bounds['NL0000-min'], per_business_bounds['NL0000-max'])

    # multiply modulated pattern by unit demand by number of units of all 3 patterns
    pattern_h1 = pattern_h1 * n_houses * per_house_demand
    pattern_h2 = pattern_h2 * n_houses * per_house_demand
    pattern_b = pattern_b * n_businesses * per_business_demand

    # return the weighted sum of the two shouse demand and the business demand
    return ((pattern_h1 * w_h1 + pattern_h2 * w_h2), pattern_b)

def age_distribution_networks(
        closing_municipalities: Set[Municipality],
        alive_municipalities: Set[Municipality],
        year: int,
        nrw_info_db: NRWModelDB
    ) -> List[Municipality]:

    # Get where the closing municipalities go, we split equally the kms of pipes
    destination_municipalities_map: Dict[Municipality, List[Tuple[float, float]]] = {}
    for closing_municipality in closing_municipalities:
        n_destinations = len(closing_municipality.destination_cbs_ids)
        for destination_id in closing_municipality.destination_cbs_ids:
            destination = closing_municipality.province.municipality( destination_id
                ).effective_entity(year+1)
            
            if destination not in destination_municipalities_map:
                destination_municipalities_map[destination] = []

            m = get_snapshot(closing_municipality, year)
            destination_municipalities_map[destination].append((
                m.dist_network_length/n_destinations,
                m.dist_network_avg_age
                ))
        
    opening_municipalities = [m for m in destination_municipalities_map if m not in alive_municipalities]
    alive_and_receiving_municipalities = [m for m in destination_municipalities_map if m in alive_municipalities]
    alive_and_untouched_municipalities = [m for m in alive_municipalities if m not in destination_municipalities_map]

    for m in alive_and_untouched_municipalities:
        m.update_dist_net_age(when=year+1, by=1)

    for m in opening_municipalities:
        data = destination_municipalities_map[m]
        data = np.array(data)
        data[:, 0] = data[:, 0]/np.sum(data[:, 0])
        avg_age = np.sum(data[:,0]*data[:,1])

        m.update_dist_net_age(
            when=year+1,
            by=avg_age+1,
            override_age=True
        )

    for m in alive_and_receiving_municipalities:
        m_y = get_snapshot(m, year)
        data = destination_municipalities_map[m]+[(m_y.dist_network_length, m_y.dist_network_avg_age)]
        data = np.array(data)
        data[:, 0] = data[:, 0]/np.sum(data[:, 0])
        avg_age = np.sum(data[:,0]*data[:,1])

        m.update_dist_net_age(
            when=year+1,
            by=avg_age+1,
            override_age=True
        )

    return opening_municipalities
